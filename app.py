import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
from sklearn.metrics import accuracy_score

# -----------------------
# æ•°æ®åŠ è½½ä¸ç¼“å­˜
# -----------------------
@st.cache_data
def load_data():
    train = pd.read_csv("sign_mnist_train.csv")
    test = pd.read_csv("sign_mnist_test.csv")
    return train, test

train, test = load_data()

# -----------------------
# æ•°æ®é¢„å¤„ç†
# -----------------------
X_train = torch.tensor(train.drop("label", axis=1).values / 255.0, dtype=torch.float32).reshape(-1, 1, 28, 28)
y_train = torch.tensor(train["label"].values, dtype=torch.long)

X_test = torch.tensor(test.drop("label", axis=1).values / 255.0, dtype=torch.float32).reshape(-1, 1, 28, 28)
y_test = torch.tensor(test["label"].values, dtype=torch.long)

letters = [chr(i) for i in range(65, 91)]

# -----------------------
# Streamlit UI
# -----------------------
st.title("ğŸ§ æ‰‹è¯­å­—æ¯è¯†åˆ« (Sign Language MNIST) â€” PyTorch ç‰ˆ")
st.write("é€šè¿‡è§†è§‰åŒ–ä¸æ·±åº¦å­¦ä¹ æ¢ç´¢æ‰‹è¯­æ•°æ®é›†")

# äº¤äº’æ§ä»¶
selected_letters = st.multiselect("é€‰æ‹©è¦æ˜¾ç¤ºçš„æ‰‹åŠ¿å­—æ¯ï¼ˆå¯å¤šé€‰ï¼‰", letters, default=["A", "B"])
num_images = st.slider("æ¯ä¸ªå­—æ¯æ˜¾ç¤ºå›¾ç‰‡æ•°", 1, 10, 5)

# -----------------------
# æ˜¾ç¤ºç¤ºä¾‹å›¾ç‰‡
# -----------------------
st.subheader("ğŸ”¹ æ‰‹åŠ¿ç¤ºä¾‹å›¾ç‰‡")
for letter in selected_letters:
    label_idx = ord(letter) - 65
    imgs = X_train[y_train == label_idx][:num_images]
    st.write(f"å­—æ¯ {letter} ç¤ºä¾‹ï¼š")
    cols = st.columns(num_images)
    for i, img in enumerate(imgs):
        cols[i].image(img.squeeze().numpy(), width=100)

# -----------------------
# EDA å¯è§†åŒ–
# -----------------------
st.subheader("ğŸ“Š æ¯ä¸ªå­—æ¯æ‰‹åŠ¿æ•°é‡ç»Ÿè®¡")
fig, ax = plt.subplots(figsize=(10,4))
sns.countplot(x="label", data=train, ax=ax, palette="coolwarm")
ax.set_xlabel("å­—æ¯æ ‡ç­¾ (0=A, 25=Z)")
ax.set_ylabel("æ•°é‡")
st.pyplot(fig)

st.subheader("ğŸ“ˆ åƒç´ å¼ºåº¦åˆ†å¸ƒç¤ºä¾‹")
plt.hist(X_train[0].flatten().numpy(), bins=20, color="purple")
plt.xlabel("åƒç´ å¼ºåº¦")
plt.ylabel("é¢‘æ•°")
st.pyplot(plt)

# å¹³å‡æ‰‹åŠ¿çƒ­åŠ›å›¾
st.subheader("ğŸ”¥ å¹³å‡æ‰‹åŠ¿å›¾åƒï¼ˆå­—æ¯ A ç¤ºä¾‹ï¼‰")
avg_img = X_train[y_train == 0].mean(dim=0).squeeze()
sns.heatmap(avg_img.numpy(), cmap="viridis")
st.pyplot(plt)

# -----------------------
# PyTorch æ¨¡å‹å®šä¹‰
# -----------------------
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 26)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# -----------------------
# æ¨¡å‹è®­ç»ƒ
# -----------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def train_model(epochs=3, batch_size=128, lr=0.001):
    model = CNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=256)

    train_acc_list, val_acc_list = [], []

    for epoch in range(epochs):
        model.train()
        correct, total = 0, 0
        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            optimizer.zero_grad()
            outputs = model(X)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()
            _, preds = torch.max(outputs, 1)
            correct += (preds == y).sum().item()
            total += y.size(0)
        train_acc = correct / total

        # æµ‹è¯•é›†å‡†ç¡®ç‡
        model.eval()
        y_pred, y_true = [], []
        with torch.no_grad():
            for X, y in test_loader:
                X, y = X.to(device), y.to(device)
                outputs = model(X)
                _, preds = torch.max(outputs, 1)
                y_pred.extend(preds.cpu().numpy())
                y_true.extend(y.cpu().numpy())
        val_acc = accuracy_score(y_true, y_pred)
        train_acc_list.append(train_acc)
        val_acc_list.append(val_acc)
        st.write(f"Epoch {epoch+1}/{epochs} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f} | æµ‹è¯•å‡†ç¡®ç‡: {val_acc:.2f}")

    return model, train_acc_list, val_acc_list

# -----------------------
# è®­ç»ƒæŒ‰é’®
# -----------------------
st.subheader("ğŸ§© PyTorch CNN è®­ç»ƒ")
if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹ (3 epochs)"):
    model, train_acc_list, val_acc_list = train_model()

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    fig, ax = plt.subplots()
    ax.plot(train_acc_list, label="è®­ç»ƒå‡†ç¡®ç‡")
    ax.plot(val_acc_list, label="æµ‹è¯•å‡†ç¡®ç‡")
    ax.set_xlabel("Epoch")
    ax.set_ylabel("å‡†ç¡®ç‡")
    ax.legend()
    st.pyplot(fig)
    st.success(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡ï¼š{val_acc_list[-1]:.2f}")
